![Markdown Logo](assets/images/algorithms-and-data-structres.jpg)
<small>Visual: Unsplash / Lorenzo Herrera</small>
<br/><br/>

<div align="center">

# **Algorithms and data structres 🧱**
 Learn and master Algorithms, Data structres, Asymptotic analysis, Recursion, Dynamic Programming, Divide and conquer and all kina awesomeness 🧃

<br>


[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://GitHub.com/Naereen/StrapDown.js/graphs/commit-activity) [![Ask Me Anything !](https://img.shields.io/badge/Ask%20me-anything-1abc9c.svg)](https://github.com/humamaboalraja) [![MIT license](https://img.shields.io/badge/License-MIT-blue.svg)](https://lbesson.mit-license.org/)


</div>

---

<br/>

## - [**Table of content**](#table-of-content)

  - 1 . [Getting started](#getting-started)
  - 2 . [Learning Checklist ✅](#learning-checklist-)
  - ## 3 . [Algorithms Applications & theory](#algorithms-applications-&-theory)
    - 3.1 . [Asymptotic Analysis](#asymptotic-analysis)
      - 1 . [Time Complexity](#time-complexity)
      - 2 . [Space Complexity](#space-complexity)
      - 3 . [Memory](#memory)
    - 2 . [Asymptotic notations](#asymptotic-notations)
      - 1 . [Big-O notation (O)](#big-O-notation-O)
      - 2 . [Omega notation (Ω)](#omega-notation-ω)
      - 3 . [Theta notation (Θ)](#theta-notation-θ)
      - 4 . [Differences between Big-O, Big-Ω and Big-Θ](#differences-between-big-O,-big-Ω-and-big-Θ)
    - 3 . [Algorithm Design Techniques & Strategies](#algorithm-design-strategies--techniques)
    - 4 . [Searching Algorithms](#searching-algorithms)
      - 1 . [Linear Search](#linear-search)
      - 2 . [Binary Search](#binary-search)
      - 3 . [Jump Search](#jump-search)
      - 4 . [A* search algorithm](#a*-search-algorithm)
      - 5 . [Ternary search](#ternary-search)
      - 6 . [Exponential search](#exponential-search)
    - 5 . [Recursion (Recursive Algorithms)](#recursion-recursive-algorithms)
      - 1 . [Differences between Recursion and Iteration](#differences-between-recursion-and-iteration)
      - 2 . [Base case](#base-case) exit condition (when do you stop recursing)
      - 3 . [General (recursive) case](#general-recursive-case) (Recurse)
    - 6 . [Sorting Algorithms](#sorting-algorithms)
      - 1 . [Bubble Sort](#bubble-sort)  
      - 2 . [Selection Sort](#selection-sort)  
      - 3 . [Insertion Sort](#insertion-sort)  
      - 4 . [Merge Sort](#merge-sort)  
      - 5 . [Quick Sort](#quick-sort)  
      - 6 . [Counting Sort](#counting-sort)  
      - 7 . [Radix Sort](#radix-sort)  
      - 8 . [Bucket Sort](#bucket-sort)  
    - 7 . [Graph Algorithms](#graph-algorithms)
      - 1 . [Breadth-first search](#breadth-first-search)
      - 2 . [Depth-first search](#depth-first-search)
      - 3 . [Dijkstra’s shortest path algorithm]()
      - 4 . [Bellman–Ford algorithm](#bellman–ford-algorithm)
    - 8 . [Greedy Algorithms](#greedy-algorithms)
    - 9 . [Divide and Conquer](#divide-and-conquer)
    - 10 . [Dynamic Programming](#dynamic-programming)
    - 11 . [Backtracking](#backtracking)
  - ## 4 . [Data structres](#data-structres)
    - 1  . [What are Data structres?](#what-are-data-structres?)
    - 2  . [Logarithm](#logarithm)
    - 3  . [Difference between Linear and Non-linear Data Structures](#difference-between-linear-and-non-linear-data-structures)
    - 4  . [Arrays](#arrays)
    - 5  . [Linked lists](#linked-lists)
      - 5.1  . [Singly Linked lists](#singly-linked-lists)
      - 5.2  . [Doubly Linked lists](#doubly-linked-lists)
      - 5.2  . [Circular Linked lists](#circular-linked-lists)
    - 6  . [Hash tables](#hash-tables)
    - 7  . [Stacks](#stacks)
    - 8 . [Queues](#queues)
    - 9 . [Trees](#trees)
      - 9.1 . [Binary search trees](#binary-search-trees)
      - 9.2 . [AVL Trees](#avl-trees)
      - 9.3 . [Heaps](#heaps)
    - 10 . [Tries](#tries)
    - 11 . [Graphs](#graphs)
    - 12 . [Strings](#strings)
    - 13 . [Priority Queue](#priority-queue)
    - 14 . [Dictionaries](#dictionaries)
    
    <br>

    #### **Further Learning Resource**

  - 5 . [Articles 📰](#-articles-)
  - 6 . [Books 📚](#-books-)
  - 7 . [Courses 💻](#-courses-)

---

<br/>

# 1

## **Getting started**

<details>
  <summary>Let's first get to know why do we need this thing 🥸 | <b>Click to expand</b></summary>
</br>

### **Why do you need any of this**


---

</details>
<br/>
<br/>
<br/>







# 2
## **Learning Checklist ✅**

<details>
  <summary>A handy checklist to keep track of your progress, and know when you master your Algorithms and data strucres path 💈. <b>Click to expand</b></summary>
</br>

### **Algorithms**:
Show that you:
- [ ]  Know how to analyze algorithms
- [ ]  Know what is algorithm time complexity
- [ ]  Applied these concepts to searching and sorting algorithms

### **Data structures**:
For each of the data structures listed below, you have to understand their functionality, including common operations and their time complexities; what are their strengths and their limitations and, finally, how they are used in real-world scenarios.

- [ ]  Arrays
  - [ ] Traversing, Searching, Insertion, Deletion, Size
- [ ]  Stacks
  - [ ]  Push, Pop, is empty, top
- [ ]  Queues
- [ ]  Linked Lists
- [ ]  Hash tables
- [ ]  Graphs
- [ ]  Trees
- [ ]  Tries



</details>

---

<br/>
<br/>



<div align="center">

# 3

## **Algorithms Applications & theory**

<br>


![](https://media.giphy.com/media/6wa5vuYvetU1Jibm13/source.gif)
---
</div>
 <h2>Algorithm</h2> 

noun, UK  /ˈæl.ɡə.rɪ.ðəm/ US  /ˈæl.ɡə.rɪ.ðəm/

>a process, step-by-step procedure or set of rules to be followed in calculations or other problem-solving operations to be executed in a certain order to get the desired output, especially by a computer, and those can be simple processes, such as multiplying two numbers, or a complex operation, such as playing  compressed video file. or a Search engine that uses proprietary algorithms to display the most relevant results from its search index for specific queries.


**<small>Cambridge dictionary/ Oxford Languages</small>**

<br>
<details>
<summary>Algorithms Applications & theory | <b>Click to expand 🔥</b></summary>

<br>

- **What:** Algorithms are a part of daily life actions, and those daily actions and everything we do is the simplest form to represent what an Algorithm is, e.g Finding you car in a parking lot , cleaning your Apartment, reading a book.
  
  ---



- **Applications**: The real power of Algorithms come in form of Digital tools, Softwares or small computer programs like, Compression algorithms in a 3D video game or Searching algorithms in Google Search engine, or sorting algorithms to sort Amazon's products based on their ratings and all the other services and digital tools that you use on daily bases.

___

- **Efficiency**: Not all algorithms are created equal, and the tricky part of an Algorithm is that there are plenty of algorithms that solve the same problem at the end, but one of them is the most efficint one to use in that spesific problem case, so to know which solution to choose and to be able to compare them, these Algorithms most be analyzed, and before before analyuzing there an important thing that you need to know what makes a good algorithm is the two most important criteria which are that it solves a problem and it does so efficintly.

    ---
- **Measuring Efficiency**: so the way we measure the effecincy of an algorithm is through using a scientific mathematical technique called **```Asymptotic analysis```**, which allows algorithms to be compared independently of a particular programming language or hardware, which will next tell us that some algorithms are  more efficient than others.


</details>

---

<br/>
<br/>




## **Asymptotic Analysis**:

</br>

**Asymptotic analysis** of an algorithm refers to defining the mathematical boundation/framing of its run-time performance. 

- Using asymptotic analysis, we can very well conclude the best case, average case, and worst case scenario of an algorithm. 


- Complexity analysis is effectively used to determine how "good, efficent, scalable, fits the design case best" an algorithm is and whether it's "better" than another one.

- determining how efficient an algorithm is usually involves finding both the **time** complexity and **space** complexity of an Algorithm.

  ---

  <br>
  <div align="center">

  ![](https://media.giphy.com/media/3o6Yg4GUVgIUg3bf7W/giphy.gif)

  ## **But before that what Asymptotic Analysis is about?**
  
  </div>
  <br>

- First what what asymptotic does really mean?! i'm guessing that you have probably heard of the word "asymptote" if not An asymptote is a "line that continually approaches a given curve but does not meet it at any finite distance, in a simpler way it is line that a curve approaches, as it heads towards infinity like that:

  <div align="center">

  ![](assets/images/asymptotic_notation/asymptotic_analysis/asymptote.png)
  </div>
  <br>
  <br>

- The idea of Asymptotic complexity and looking at an asymptotic behavior is that we want to see how does the graph behave getting into very large inputs (n) values, and this is simply the idea of asymptotic complexity. 
  
- So why don’t we in this case to save some time measure the **elapsed real time**, like for instance measuring how fast your code ran on your machine which can tell you how strong your algorithm is!? Because it's not the effecint approach to approach Complexity analysis.

- in computer science problems are often applied at a grand scale like for instance if we are writing an algorithm to optimize whatever part of **Google’s** search engine it’s going to be used across billions of users, and there will be large inputs to the algorithms. 
  
- Our most important point is to see how does this algorithm behave on the tail end ( as (input) gets very large), cause we can only see the true measure of performance of an algorithm when we have very large data input, and that why asymptotic complexity analysis intrigues us ❤️ 

- So in order to be able to indicate the correct Asymptotic Analysis of an algorithm there are some rules that you need to follow: 

  1. We measure as a function of $n$, and ignore low order terms, and that's why we drop constants, which is the reason too why:

     - $5n^3 + n$  − 6 becomes $n^3$

     - $8n log n$  − $60n$ becomes $n log n$
     - $2^n + 3n^4$  − becomes $2^n$
      - because when we say $(O(log n), o(n), O(n2),  O(n3), O(2n), o(n!))$ we are not actually describing an individual graph, or a case that is based on a constant value, what we are really describing is a class of functions and behaviors, and that’s why these functions will have the same behaviour when we get a very large input 😉
  2. 
  3. 
  4. $ 




  <br>

  ## **An example of Asymptotic Behaviour**
  ---

  ```Insertion Sort:``` $2 * n^2$  | ```Merge Sort:``` $50 * n * log(n)$
    
    ---

  We have 2 computers: 🖥

  - **Computer A**: runs 10 Billion instructions / second

  - **Computer B**:  runs 10 Million instructions / second

  - **Computer A** is 1000x faster than **Computer B**

  - **Computer A** runs insertion sort, **Computer B** runs merge sort

  - How long will each computer take to sort 10 million numbers?

  - **Computer A**: 5.5 hours
  - **Computer B**: 20 minutes

  A computer that runs **1000x** faster lost horrendously to a computer that runs **1000x** slower than it.

  But the thing is that insertion sort will be faster for an initial amount, but it will lose as the input gets larger (and that's what we care about and what is a true expression of its efficiency).

  ---


</details>
<br/>

### **Time complexity**:
<details>
  <summary>What time complexity is? | <b>Click to expand</b></summary>
</br>
</details>

</br></br>


### **Space complexity**:
<details>
  <summary>What time complexity is? | <b>Click to expand</b></summary>
</br>
</details>


</br></br>


### **Memory**:
<details>
  <summary>What you need to know about memory? | <b>Click to expand</b></summary>
</br>
</details>

</br>

---

</details>
<br/>
<br/>




## **Asymptotic Notations**:

**Recap:** as we've mentioned in ther Asymptotic analysis section The **efficiency** of an algorithm depends on the amount of time, storage and other resources required to execute the algorithm, and an algorithm may not have the same performance for different types of inputs. With the increase in the input size, the performance will change, now this efficiency is measured with the help of Asymptotic Notations 🔥

---

<br>

**Asymptotic Notations** are Mathematical notations that are used to describe the running time of an algorithm when the input tends towards a particular value or a limiting value.

### for example: 

1. In Bubble sort algorithm which we will get to it later, when the input array is already sorted, the time taken by the algorithm is linear i.e. the best case.

2. But, when the input array is in reverse condition, the algorithm takes the maximum time (**quadratic**) to sort the elements i.e. the worst case.

3. When the input array is neither sorted nor in reverse order, then it takes average time. These durations are denoted using asymptotic notations.

  ---
<br>

### There are mainly three asymptotic notations which are 🧃:
<br>

- ### **Big-O notation (𝑂)**: 🤕 (Asymptotic Upper bound)
  <details open>
    <summary>Big-O notation (O) with code examples | <b>Click to expand</b></summary>

    <br>


    **Big-O**: notation is the formal way to represent the upper bound of the running time of an algorithm. Thus, It measures the worst case time complexity or the longest amount of time an algorithm can possibly take to complete.

    -  Big O notation is usually understood to describe the **worst-case**, complexity of an algorithm, even though the worst-case complexity might differ from the **average-case** complexity.
    - Variables used in Big O notation denote the sizes of inputs to algorithms. For example, **O(n)**  might be the time complexity of an algorithm that traverses through an array of length **n**; similarly, O(n + m) might be the time complexity of an algorithm that traverses through an array of length **n**  and through a string of length **m**
    
    -  e.g. some sorting algorithms have different time complexities
  depending on the layout of elements in their input array. In rare cases, their
  time complexity will be much worse than in more common cases. Similarly, an
  algorithm that takes in a string and performs special operations on uppercase
  characters might have a different time complexity when run on an input string
  of only uppercase characters vs. on an input string with just a few uppercase
  characters.
  - when describing the time complexity of an algorithm, it's helpful somtimers to specify what the time complexity refers to. the average case or to the worst case (e.g., "this algorithm runs in O(nlog(n)) time on average and in $O(n^2)$ time in the worse case").

  <br>
  <br>
  <br>

   <!-- <details> -->
    ![](assets/images/asymptotic_notation/big_o/big-o-notation.png)
    </br>
    

  1. ### **Big O cheatsheet**


      <details>
        <summary>Big-O Complexity table ✨ | <b>Click to expand</b></summary>
        </br>


      The following are examples of common complexities and their Big O notations,ordered from fastest to slowest:

      Big O Notation	| Name | Example(s) | Efficiency | Code example|
      |----------------|------|-----------| -------| ----|
      O(1) | Constant | 	Odd or Even number, <br> Look-up table (on average) | 🟩 | Python, Javascript
      O(log(n)) | Logarithmic | Finding element on sorted array with binary search | 🟩 | Python, Javascript
      O(n) | Linear | Find max element in unsorted array. <br> Duplicate elements in array with Hash Map | 🟩 | Python, Javascript
      O(nlog(n)) | Linearithmic | Python, Javascriptorting elements in array with merge sort | 🟩 | Python, Javascript
      O(n<sup>2</sup>) | Quadratic | # Duplicate elements in array **(naïve)**, <br> Sorting array with bubble sort | 🟨 | Python, Javascript
      O(n<sup>3</sup>) | Cubic | 3 variables equation solver | 🟨 | Python, Javascript
      O(2<sup>n</sup>) | Exponential | Find all subsets | 🟥 | Python, Javascript
      O(n!) | Factorial | Find all permutations of a given set/string | 🟥 | Python, Javascript
      </details>

      ---
  <br>

  2. ### **Big O code examples**
     Quick & Simple examples that represent the common complexities, and feel free to come back to these examples after diving deep in each algorithm in the coming sections. Ordered from the fastest to the slowest.

      <details>
        <summary> Python 🐍 | <b>Click to expand</b></summary>
        <br>
        
        ## **1.** O(N) time complexity</div>
        
        <small>Linear Search/ [Programming Simplified](programmingsimplified.com)</small>
        ![](assets/images/algorithms/linear-search.gif)

        <details>
        <summary>Implementation</summary>
        
        

        ```python

        '''
        Sample input/ Output:

        Input : arr[] = {10, 20, 80, 30, 60, 50, 
                  110, 100, 130, 170}
                  x = 110;
        Output : 6
        Element x is present at index 6
        _________________

        Input : arr[] = {10, 20, 80, 30, 60, 50, 
                    110, 100, 130, 170}
                  x = 175;
        Output : -1
        Element x is not present in arr[].
        ___________________________________
      
      Steps:

      - Start from the leftmost element of arr[] and one by one compare x with each element of arr[] 

      - If x matches with an element, return the index.

      - If x doesn’t match with any of elements,return -1.

      Steps extended:

      Step 1: Set i to 1
      Step 2: if i > n then go to step 7
      Step 3: if A[i] = x then go to step 6
      Step 4: Set i to i + 1
      Step 5: Go to Step 2 |The linear fashion|
      Step 6: Print Element x Found at index i and go to step 8
      Step 7: Print element not found
      Step 8: Exit

      The time complexity of linear search algorithm is O(n) cause it's looking for the data in a linear fashion,
      
      which means it will keep on looking until it matches with the given input.
      '''      

       def linearSearch(arr, x):
           # Linearly search x in arr[] 
           for i in range(len(arr)): # o(n) linear time
               # If x is present, which is our input for the function
               if arr[i] == x:
                   # then return its location 
                   return i

           return -1

       listOfItemsToSearchIn = [2,9,35,16,2,7,8,22,35,46,57,68,34,213,4,13] # Size N = 15

       matchedIndex = linearSearch(listOfItemsToSearchIn, 13)

       print(matchedIndex)

       # Result: 15

        ```
        </details>

      ---
        ## **2.** O(log(n)) time complexity/ Binary Search</div>

        <small>Binary Search</small>
        ![](assets/images/algorithms/binary_search/binary-search.jpeg)

        <details>
        <summary>Recursive implementation</summary>

        ```python

        '''
      
      Steps:

      1 - Start from the leftmost element of array[] and one by one compare target with each element of array[] 

      2 - If target matches with an element, return the index.

      3 - If target doesn’t match with any of elements,return -1.



      '''      

      def binarySearchHelper(array, target, left, right):

          # Element is not present in the list
          if left > right:
            return - 1
          

          middle = (left + right) // 2
          potentialMatch = array[middle]

          # If element is present at the middle itself
          if target == potentialMatch:
              return middle
          
          # If element is smaller than middle, then it can only
          # be present in left subarray
          elif target < potentialMatch:
              return binarySearchHelper(array, target, left, middle - 1)
              
          # Else the element can only be present in right subarray
          else:
              return binarySearchHelper(array, target, middle + 1, right)

      def binarySearch(array, target):
        return binarySearchHelper(array, target, 0, len(array) - 1)



      # Test list
      array = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]
      target = 15

      # Function call
      result = binarySearch(array, target)

      if result != -1:
        print("Element is present at index", str(result))
      else:
        print("Element is not present in array")


       # Result: 15

        ```
        </details>

        <details>
        <summary>Iterative implementation</summary>
        
        ```python


        ```
        </details>

      </details>
    </details>

  ---
  <br>

  ### **Omega notation (Ω)**: 😌 (Asymptotic Lower bound)

  <details>
    <summary>What is Omega notation (Ω) | <b>Click to expand</b></summary>
    </br>
  </details>

  ---

  <br>

  ### **Theta notation (Θ)**: 💈 (Asymptotic Tight (exact) bound))
  <details>
    <summary>What Asymptotic Analysis is? | <b>Click to expand</b></summary>
    </br>
  </details>
  
  ---
<br/>

  ## **Differences between Big-O, Big-Ω and Big-Θ**

  a table that explains the diffrerences between most common asymptotic notations

  <br>

  Big Oh | Big Omega | Big Theta 
  --------|-------------|--------|
  (It is like <=)  rate of growth of an algorithm is less than or equal to a specific value. | It is (like >=) rate of growth is greater than or equal to a specified value | (It is like ==) meaning the rate of growth is equal to a specified value.
  The upper bound of algorithm is represented by Big O notation. Only the above function is bounded by Big O. asymptotic upper bond is it given by Big O notation.| The algorithm’s lower bound is represented by Omega notation. The asymptotic lower bond is given by Omega notation. | The bounding of function from above and below is represented by theta notation. The exact asymptotic behavior is done by this theta notation.
  Big oh (O) – Worst case	| Big Omega (Ω) – Best case | Big Theta (Θ) – Average case
  Big-O is a measure of the longest amount of time it could possibly take for the algorithm to complete. | Big- Ω is take a small amount of time as compare to Big-O it could possibly take for the algorithm to complete. | Big- Θ is take very short amount of time as compare to Big-O and Big-? it could possibly take for the algorithm to complete.
  Mathematically – Big Oh is ```0 <=f(n) <= c g(n) for all n>=n0```	| Mathematically – Big Omega is ```O<= C g(n) <= f(n) for all n>=n 0```	| Mathematically – Big Theta is ```O<=C 2 g(n)<=f(n)<=C 1 g(n) for n>=n 0```





<br/>
<br/>




## **Algorithm design strategies & Techniques**:

<details>
  <summary>What Asymptotic Analysis is? | <b>Click to expand</b></summary>
</br>

</details>
<br/>

---

<br/>
<br/>
<br/>
<br/>



# 4

## **Searching Algorithms**:

<details>
<summary>Searching Algorithms explanation & examples</summary>

  <br>
  
  ### **Linear Search**: 

  <details>
    <summary>What Linear Search with examples | <b>Click to expand</b></summary>
    </br>
  </details>

  <br>
  
  ---

  

  ### **Binary search**:

 <details>
   <summary>What is Binary search with examples | <b>Click to expand</b></summary>
   </br>
 </details>

   <br>
  
  ---

  

  ### **Jump Search**: 

 <details>
   <summary>What Jump Search with examples | <b>Click to expand</b></summary>
   </br>
 </details>


   <br>
  
  ---

  

  ### **A<sup>*</sup> Search Algorithm**: 

 <details>
   <summary>What is A* Search Algorithm | <b>Click to expand</b></summary>
   </br>
 </details>


   <br>
  
  ---

  

  ### **Ternary search**: 

 <details>
   <summary>What is Ternary search with examples | <b>Click to expand</b></summary>
   </br>
 </details>


   <br>
  
  ---

  

  ### **Exponential search**: 

 <details>
   <summary>What is Exponential search with examples | <b>Click to expand</b></summary>
   </br>
 </details>

  <br>
<br/>

---


</div>
</details>
<br/>
<br/>
<br/>
<br/>



# 5

## **Recursion (Recursive Algorithms)**:
  

<details>
<summary>Recursion cases, explanation & examples</summary>

  <br>

  ### **Differences between Recursion and Iteration**:
  <details>
    <summary> | <b>Click to expand</b></summary>
    </br>

  Property | Recursion | Iteration
  ---------|-----------|------------
  **Definition**|	Function calls itself.|	A set of instructions repeatedly executed.
  **Application**|	For functions.|	For loops.
  **Termination**|	Through base case, where there will be no function call.|	When the termination condition for the iterator ceases to be satisfied.
  **Usage**|	Used when code size needs to be small, and time complexity is not an issue.|	Used when time complexity needs to be balanced against an expanded code size.
  **Code Size** |	Smaller code size|	Larger Code Size.
  **Time Complexity**|	Very high(generally exponential) time complexity.|	Relatively lower time complexity(generally polynomial-logarithmic).|



  </details>

  ---

  <br>

  ### **Base case**:
  <details>
    <summary>Differences between Recursion and Iteration | <b>Click to expand</b></summary>
    </br>
  </details>

  ---

  <br>

  ### **General (recursive) case**:
  <details>
    <summary>Differences between Recursion and Iteration | <b>Click to expand</b></summary>
    </br>

  ---

  </details>




<br/>


</details>
---
<br/>
<br/>
<br/>



# 6


## **Sorting Algorithms**:

<details>
<summary>Sorting Algorithms explanation and examples</summary>
<br>

---
  
  ### **Bubble Sort**: 

  <details>
    <summary>What Bubble Sort with examples | <b>Click to expand</b></summary>
    </br>
  </details>

  <br>
  
  ---

  

  ### **Selection Sort**:

 <details>
   <summary>What is Selection Sort with examples<b>Click to expand</b></summary>
   </br>
 </details>

   <br>
  
  ---

  

  ### **Insertion Sort**: 

 <details>
   <summary>What Insertion Sort with examples | <b>Click to expand</b></summary>
   </br>
 </details>


   <br>
  
  ---

  

  ### **Merge Sort**: 

 <details>
   <summary>What is Merge Sort with examples | <b>Click to expand</b></summary>
   </br>
 </details>


   <br>
  
  ---




  ### **Quick Sort**: 

 <details>
   <summary>What is Quick Sort with examples | <b>Click to expand</b></summary>
   </br>
 </details>

   <br>
  
  ---



  ### **Radix Sort**: 

 <details>
   <summary>What is Radix Sort with examples | <b>Click to expand</b></summary>
   </br>
 </details>


   <br>
  
  ---



  ### **Counting Sort**: 

 <details>
   <summary>What is Radix Sort with examples | <b>Click to expand</b></summary>
   </br>
 </details>

   <br>
  
  ---

  

  ### **Bucket Sort**: 

 <details>
   <summary>What is Bucket Sort with examples | <b>Click to expand</b></summary>
   </br>
 </details>

   <br>
</details>

  ---
 
 
  <br>
<br/>
<br/>
<br/>


# 7

## **Graph Algorithms**:

  <br>

<details>
<summary>Graph Algorithms explanation and examples</summary>
<br>

---
  


  ### **Breadth-first search**:
  <details>
    <summary> | <b>Click to expand</b></summary>
    </br>

  </details>

  ---

  <br>

  ### **Depth-first search**:
  <details>
    <summary>Differences between Recursion and Iteration | <b>Click to expand</b></summary>
    </br>
  </details>

  ---

  <br>

  ### **Dijkstra’s shortest path algorithm**:
  <details>
    <summary>Differences between Recursion and Iteration | <b>Click to expand</b></summary>
    </br>

  ---

  </details>


  ---

  <br>

  ### **Bellman–Ford algorithm**:
  <details>
    <summary>Differences between Recursion and Iteration | <b>Click to expand</b></summary>
    </br>

  ---

  </details>




<br/>

</details>
---

  <br>
<br/>
<br/>
<br/>



# 8

## **Divide and Conquer**:

  <br>




  ### **Breadth-first search**:
  <details>
    <summary> | <b>Click to expand</b></summary>
    </br>

  </details>

  ---

  <br>
<br/>
<br/>
<br/>


# 9

## **Dynamic Programming**:

  <br>




  ### **Breadth-first search**:
  <details>
    <summary> | <b>Click to expand</b></summary>
    </br>

  </details>

  ---

  <br>
<br/>
<br/>
<br/>


# 10

## **Backtracking**:

  <br>




  ### **Breadth-first search**:
  <details>
    <summary> | <b>Click to expand</b></summary>
    </br>

  </details>

  ---

<br/>
<br/>
<br/>








# 8
## **Articles 📰**

___

Article           | Provider (Platform) | Used as reference|
--------------------- | -------------- | -------|
[Difference between Big Oh, Big Omega and Big Theta](https://www.tutorialspoint.com/data_structures_algorithms/asymptotic_analysis.htm) | Tutorialspoint | Yes
[Difference between Recursion and Iteration](https://www.geeksforgeeks.org/difference-between-recursion-and-iteration/) | Geeksforgeeks | Yes
[Difference between Big Oh, Big Omega and Big Theta](https://www.geeksforgeeks.org/difference-between-big-oh-big-omega-and-big-theta/) | Geeksforgeeks | Yes

___
<br/><br/><br/>

# 9
## **Books 📚**
One of the most straight to the point Books 🔥🕹📟
___

Book name           | Provider (Platform) | Author| Skill level |  Cost
--------------------- | -------------- | -------- | ---------- | -----
[The Algorithm Design Manual](https://www.amazon.com/-/en/Steven-S-S-Skiena/dp/1849967202) | Amazon | Steven S S. Skiena | Intermediate | $75.98 |
[Grokking Algorithms: An Illustrated Guide for Programmers and Other Curious People](https://www.amazon.com/-/en/Aditya-Bhargava/dp/1617292230) | Amazon | Aditya Bhargava | Beginner | $39.86 |
___

<br/> 

# 10

## **Courses 💻**
----
The most popular courses that teach Algorithms and data structres. Yes for real 🔥🕹📟

Course name           | Provider (Platform) | Duration| Skill level | Course Cost
--------------------- | -------------- | -------- | ---------- | -----
[Intro to Data Structures and Algorithms](https://www.udacity.com/course/data-structures-and-algorithms-in-python--ud513) | [Udacity]([educative.io](https://www.udacity.com/)) | 4 | Beginner | Free |
[Ace the Python Coding Interview](https://www.educative.io/path/ace-python-coding-interview) | [educative](educative.io) | 21h | Beginner |  |

---

<br/><br/><br/>

# 11

<!-- Tables -->
## **Resources**
**Resources** to learn Algorithms and data structres from 🐱
<br/>

---
<br/>

> Learn by Watching/ Doing/ Reading
>
Title | Description
------------ | -------------
[Data Structures Crash Course (Algoexpert.io)](https://www.algoexpert.io/data-structures) | The foundational knowledge you need to ace the coding interviews.
[Asymptotic Analysis: Big-O Notation and More](https://www.programiz.com/dsa/asymptotic-notations) | In this tutorial, you will learn what asymptotic notations are. Also, you will learn about Big-O notation, Theta notation and Omega notation.
[What Is Asymptotic Analysis? And Why Does It Matter? A Deeper Understanding of Asymptotic Bounding.](https://www.youtube.com/watch?v=myZKhztFhzE) | What Asymptotic Analysis Is!
[YouTube channel: Back To Back SWE](https://www.youtube.com/channel/UCmJz2DV1a3yfgrR7GqRtUUA) | A very helpful youtube channel to learn and understand Asymptotic Bounding, logratihms, sorting algorithms etc..
[Animated Algorithms and Data Structures by Chris Laux.](https://www.chrislaux.com/) | A interactive website explaining some sorting algorithms and some data structures.
[Recursion in software development](https://livevideo.manning.com/module/31_3_1/algorithms-in-motion/recursion/recursion?) | To understand recursion you must first understand recursion
---
